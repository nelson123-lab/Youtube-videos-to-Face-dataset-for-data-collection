# -*- coding: utf-8 -*-
"""Programming assignment 3.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10b_pm6Bm0kIzruV7M5Hvq21xdcOc--KD
"""



if __name__ == "__main__":
  
  #Import statements.
  
  import sys
  #import matplotlib
  import numpy as np
  #import matplotlib.pyplot as plt
  import pandas as pd
  from sklearn.preprocessing import StandardScaler

  #in Debuggin purpose
  #sys.argv[1] = 'yeast_test.txt'
  #sys.argv[2] = 2
  #sys.argv[3] = 5
  #filename = 'yeast_test.txt'
  #clusternum = 6
  #iter_num = 10

#Set the path  to local directory or cloud location
  path = r'C:/Users/NELSON JOSEPH/Downloads/UCI_datasets-20221214T030257Z-001/UCI_datasets/'
  filename = 'yeast_test.txt'

  #read argument module
  if(len(sys.argv) == 4):
    filename = sys.argv[1]
    clusternum = int(sys.argv[2])
    iter_num = int(sys.argv[3])
  else:
    print("Error in number of attributes. Run again with correct attributes at command line")
  # Set random seed so output is all same
  np.random.seed(1)

#Defining the class for KMeans object implementation.
  class KMeans(object):

      def __init__(self):  
          pass
#Takes the euclidean distance between two points given.
      def euclidean_dist(self, x, y):  

          x_squaredsum = np.sum(np.square(x),axis=1, );
          y_squaredsum = np.sum(np.square(y),axis=1, );
          mult_vec = np.dot(x, y.T);
          dists = np.sqrt(abs(x_squaredsum[:, np.newaxis] + y_squaredsum-2*mult_vec)) 
          return dists

#Function to select initial centroid by random partition method
      def _init_centers(self, points, K, **kwargs):  
          
          row, col = points.shape
          init_clusterarray = np.empty([K, col])
          for num in range(K):
              random_point = np.random.randint(row)
              init_clusterarray[num] = points[random_point]
          
          return init_clusterarray

#FUnction to update cluster assignment based on average distances.
      def _update_clusterassignment(self, centers, points):  
          row, col = points.shape
          clusterIDs = np.empty([row])
          dist_points = self.euclidean_dist(points, centers)
          clusterIDs = np.argmin(dist_points, axis=1)

          return clusterIDs

#Function to update cluster center based on previous calculations.
      def _update_clusterCenter(self, prev_centers, clusterIDs, points):  
        
          K, D = prev_centers.shape
          new_centers = np.empty(prev_centers.shape)
          for i in range(K):
              new_centers[i] = np.mean(points[clusterIDs == i], axis = 0)
          return new_centers

#Calculating the error value generated from distance metrics.
      def _get_error_gen(self, centers, clusterIDs, points):  
          
          distances = self.euclidean_dist(points, centers)
          error_gen = 0.0
          N, D = points.shape
          for i in range(N):
              error_gen = error_gen + np.square(distances[i][clusterIDs[i]])
          
          return error_gen

#Default calling function of the class. Takes some arguments and pro
      def __call__(self, points, K, max_iters=100, abs_tol=1e-16, rel_tol=1e-16, **kwargs):
          
          centers = self._init_centers(points, K, **kwargs)
          clusterIDs = self._update_clusterassignment(centers, points)
          error_gen = self._get_error_gen(centers, clusterIDs, points)
          print('After initialization: error = %.4f' % error_gen )
          prev_error_gen = error_gen
          for iteration in range(max_iters):
              clusterIDs = self._update_clusterassignment(centers, points)
              centers = self._update_clusterCenter(centers, clusterIDs, points)
              error_gen = self._get_error_gen(centers, clusterIDs, points)
              
              K = centers.shape[0]
              if iteration:
                  diff_error = np.abs(prev_error_gen - error_gen)
                  if diff_error < abs_tol and diff_error / prev_error_gen < rel_tol:
                      break
              prev_error_gen = error_gen
            
              print('After iteration %d: error = %.4f' % (iteration+1, error_gen))
          
#Data loading using system provided argument filename attached with path 

  dataset = pd.read_csv(path+filename,delim_whitespace=True)
  dataset.head()

#Removing the last coloumn since it is a label and considering rest of the data
  true_labels = dataset.iloc[: , -1]
  yeast = dataset.iloc[:,:-1]

#Preprocessing the data for fitting the model.
  X_train, true_labels = yeast, true_labels
  X_train = StandardScaler().fit_transform(X_train)

#Calling the object with passed on arguments

  kmeans = KMeans()
  kmeans(points = X_train, K = clusternum, max_iters = iter_num )




########################################################################
######################### References ###################################

#1.https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
#2.https://stackoverflow.com/questions/57507584/feature-scaling-for-kmeans-algorithm
#3 K Means Clustering Call function and random seed referenced from 
#https://github.com/paulestano/CS-7641/blob/master/
#4.https://www.geeksforgeeks.org/clustering-in-machine-learning/?ref=lbp

# Fit centroids to dataset

